---
title: "group_project_1_ricco_ferraro"
author: "Ricco Ferraro"
date: "1/30/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
  
Libraries
```{r}
library(leaps)
library(magrittr) # makes the pipe %>% work
library(ggplot2)
library(tidyverse)
library(reshape2)
library(car)     # where vif function lives
library(ISLR)
library(leaps)
library(dplyr)
library(doBy)
library(e1071)
library(class)
library(caret)
library(Metrics)
library(gtools)
library(glmnet)
library(kableExtra)
library(coefplot)
library(data.table)
library(plotmo)
library(ggfortify)
library(olsrr)

```

Data I/O
```{r}
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
CaseData = read.csv('data1.csv',header = T,sep = ",", stringsAsFactors = TRUE)
```


Summary Stats Original Data
```{r}
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
CaseData = data.frame(CaseData, stringsAsFactors = TRUE)

CaseData %>% ggplot(aes(x=Year, y=MSRP, fill = Vehicle.Style)) + geom_boxplot() + theme_dark() 
facet_wrap(~Driven_Wheels) 

CaseData %>% ggplot(aes(x=Engine.Cylinders, y=MSRP,color=Year))+ geom_point() + facet_wrap(~Driven_Wheels) + theme_dark()


CaseData %>% ggplot(aes(x=Engine.Cylinders, y=MSRP,color=Year))+ geom_point()+ theme_dark()

#remove_missing(CaseData)

classifyDATA <- CaseData[,c(3,5,6,9,13,14,15)]
classifyDATA$Response <- CaseData[,c(16)]

glimpse(classifyDATA)

#M <- cor(CaseData)
#corrplot(M, col=brewer.pal(n=6, name="RdYlBu"),tl.cex = .75)

sapply(CaseData, function(x) length(unique(x)))

count_pct <- function(df) {
  return(
    df %>%
      tally %>% 
      mutate(n_pct = 100*n/sum(n))
  )
}

CaseData %>% 
  group_by(Transmission.Type) %>% 
  count_pct


CaseData %>% 
  group_by(Driven_Wheels) %>% 
  count_pct

CaseData %>% 
  group_by(Number.of.Doors) %>% 
  count_pct


CaseData %>% 
  group_by(Vehicle.Size) %>% 
  count_pct

CaseData %>% 
  group_by(Engine.Fuel.Type) %>% 
  count_pct


CaseData %>% 
  group_by(Vehicle.Style) %>% 
  count_pct


colnames(is.na(CaseData))

#CHANGE TO THE IS 0 , NA 
which (is.na(CaseData))

CaseData %>%
  summarise_all(funs(sum(is.na(.))))

skewness(CaseData$MSRP)
skewness(CaseData$Popularity)

CaseData$Popularity2 <- as.factor(CaseData$Popularity)

CaseData %>% ggplot(mapping = aes(x=Popularity)) + geom_histogram(binwidth =250 )

#CaseData %>% ggplot(mapping = aes(x=Popularity2, fill = Market.Category)) + geom_histogram(binwidth =250 )

glimpse(CaseData)

CaseData %>% ggplot(mapping = aes(x=MSRP)) + geom_histogram(binwidth =250 )

model.fit<-aov(MSRP~Popularity2,data=CaseData)
#par(mfrow=c(2,2))
#plot(model.fit$fitted.values,model.fit$residuals,ylab="Resdiduals",xlab="Fitted")
#qqnorm(model.fit$residuals)

par(mfrow=c(2,2))
plot(model.fit)


model2.fit<-lm(MSRP~Popularity2,data=CaseData)
#par(mfrow=c(2,2))
#plot(model.fit$fitted.values,model.fit$residuals,ylab="Resdiduals",xlab="Fitted")
#qqnorm(model.fit$residuals)

par(mfrow=c(2,2))
plot(model2.fit)


mysummary<-function(x){
  result<-c(length(x),mean(x),sd(x),sd(x)/length(x),min(x), max(x), IQR(x))
  names(result)<-c("N","Mean","SD","SE","MIN", "MAX","IQR")
  return(result)
}

#sumstats<-aggregate(MSRP~Cylinders,data=CaseData,mysummary)
#sumstats<-cbind(sumstats[,1:2],sumstats[,-(1:2)])

# ggplot(sumstats,aes(x=DepthCat,y=Mean,group=Strata,colour=Strata))+
#  ylab("Plot")+
# geom_line()+
# geom_point()+
# geom_errorbar(aes(ymin=Mean-SE,ymax=Mean+SE),width=.1)
```

Filter and Impute the Data
```{r}
isEmpty <- function(column) {
    is.na(column) | column == 0 | column == "" | column == " " | column == "NA" | column == "na" | column == "Na" | column == "nA" | column == "NaN" 
}

bucketFuelType <- function(fuelType) {
  regexPremium = "premium"
  regexNonPremium= "diesel|electric|unleaded"
  if_else(str_detect(fuelType, regexPremium), "premium", 
          if_else(str_detect(fuelType, regexNonPremium), str_extract(fuelType, regexNonPremium),
                  "other")
  )
}

#Filter out old cars
CaseData
CaseData %>% filter(MSRP > 2000) -> CaseData.NewCars.1
CaseData.NewCars = data.frame(CaseData.NewCars.1, stringsAsFactors = TRUE)

# filter Fuel.Type
CaseData.NewCars %>% filter(!isEmpty(Engine.Fuel.Type) & Engine.Fuel.Type != "natural gas") -> CaseData.NewCars.Filtered
CaseData.NewCars.Filtered

# summary known Engine.Hp's
Vehicle.Size.Summary <- CaseData.NewCars.Filtered %>% filter(!isEmpty(Engine.HP)) %>% group_by(Vehicle.Size) %>% summarise(median_hp_by_vehicle_size=median(Engine.HP)) 

# look at our summary
Vehicle.Size.Summary

#Impute values for Engine.HP by Vehicle.Size (for median Engine.HP)

CaseData.NewCars.Filtered.ImputedHP <-merge(CaseData.NewCars.Filtered, Vehicle.Size.Summary, by="Vehicle.Size")  %>% mutate(Engine.HP.Clean = if_else(isEmpty(Engine.HP), median_hp_by_vehicle_size, as.double(Engine.HP)))
CaseData.NewCars.Filtered.ImputedHP

# summary known Engine.Cylinders
Vehicle.Size.Summary <- CaseData.NewCars.Filtered.ImputedHP %>% filter(!isEmpty(Engine.Cylinders)) %>% group_by(Vehicle.Size) %>% summarise(median_cylinder_by_vehicle_size=median(Engine.Cylinders)) 

# look at our summary
Vehicle.Size.Summary

#Impute values for Engine.HP by Vehicle.Size (for median Engine.HP)
CaseData.NewCars.Filtered.ImputedHP$Engine.Cylinders <- as.double(CaseData.NewCars.Filtered.ImputedHP$Engine.Cylinders)
CaseData.NewCars.Filtered.ImputedHPAndCylinders <-merge(CaseData.NewCars.Filtered.ImputedHP, Vehicle.Size.Summary, by="Vehicle.Size")  %>% mutate(Engine.Cylinders.Clean = if_else(isEmpty(Engine.Cylinders), as.double(median_cylinder_by_vehicle_size), Engine.Cylinders))

#Doors (This mutates CaseData.NewCars.Filtered.ImputedHPAndCylinders)
CaseData.NewCars.Filtered.ImputedHPAndCylinders <- CaseData.NewCars.Filtered.ImputedHPAndCylinders %>% mutate(NumDoors.Clean=if_else((Make == 'Tesla' | Make == 'Ferrari') & isEmpty(Number.of.Doors), 4, as.numeric(Number.of.Doors))) 

CaseData.NewCars.Filtered.ImputedHPAndCylinders$Engine.Cylinders.Clean <- as.factor(CaseData.NewCars.Filtered.ImputedHPAndCylinders$Engine.Cylinders.Clean)
CaseData.NewCars.Filtered.ImputedHPAndCylinders$NumDoors.Clean <- as.factor(CaseData.NewCars.Filtered.ImputedHPAndCylinders$NumDoors.Clean)

#Bucket Engine.Fuel.Type NOTE we aren't currently using this. 
CaseData.NewCars.Filtered.ImputedHPAndCylindersAndFuelType <- CaseData.NewCars.Filtered.ImputedHPAndCylinders %>% filter(Engine.Fuel.Type != "electric" & highway.MPG < 100) %>%  mutate(Engine.Fuel.Type.Buckets=as.factor(bucketFuelType(Engine.Fuel.Type)))

summary(CaseData.NewCars.Filtered.ImputedHPAndCylindersAndFuelType)
myData <- CaseData.NewCars.Filtered.ImputedHPAndCylindersAndFuelType[, c('Vehicle.Size','Year', 'Engine.Fuel.Type', 'Transmission.Type', 'Driven_Wheels', 'Vehicle.Style', 'highway.MPG', 'city.mpg', 'Popularity', 'Engine.HP.Clean', 'Engine.Cylinders.Clean', 'NumDoors.Clean', 'MSRP')]
myData <- myData %>% filter(Year > 2000 & MSRP < 100000)
summary(myData)
```

## Summary of Data Before and After Impuding (Data Prep Continued)
```{r}
CaseData.NewCars.Filtered.ImputedHPAndCylinders -> A

# This can be placed in the main document
# Summary of Data Before and After Imputing
ktable <- data.frame(
  Horsepower = matrix(summary(A$Engine.HP)),
  HorsepowerClean = c(matrix(summary(as.double(A$Engine.HP.Clean))),"-"),
  Cylinders = matrix(summary(A$Engine.Cylinders)),
  CylindersClean = c(matrix(summary(as.numeric(A$Engine.Cylinders.Clean))),"-"),
  Doors =	matrix(summary(A$Number.of.Doors)),
  DoorsClean = c(matrix(summary(as.numeric(A$NumDoors.Clean))),"-")
)%>%
 kbl() %>%
  kable_styling(bootstrap_options = c("striped", "hover"), font_size = 12)%>%
    add_header_above(c("Summary Data Continued" = 6))
ktable

# data.frame(summary(CaseData.NewCars))
# data.frame(matrix(summary(CaseData.NewCars)))

```


``` {r}
myModelHP = lm(log(MSRP) ~ .-Engine.HP -Engine.Cylinders -Make -Number.of.Doors -Model -Engine.Fuel.Type -Market.Category -Popularity2 -median_cylinder_by_vehicle_size -median_hp_by_vehicle_size, data = myData)
predicted <- predict.lm(myModelHP)
summary(myModelHP)

vif(myModelHP)
```

``` {r}

count_pct <- function(df) {
  return(
    df %>%
      tally %>% 
      mutate(n_pct = 100*n/sum(n))
  )
}

myData %>% 
  group_by(Engine.Cylinders.Clean) %>% 
  count_pct


myData %>% 
  group_by(Transmission.Type) %>% 
  count_pct


myData %>% 
  group_by(Driven_Wheels) %>% 
  count_pct

myData %>% 
  group_by(Number.of.Doors) %>% 
  count_pct


myData %>% 
  group_by(Vehicle.Size) %>% 
  count_pct

myData %>% 
  group_by(Engine.Fuel.Type) %>% 
  count_pct


myData %>% 
  group_by(Vehicle.Style) %>% 
  count_pct



```


```{r}

myModel2 = lm(log(MSRP) ~ .-Engine.HP -Engine.Cylinders -Make -Vehicle.Style -Number.of.Doors -Model -Market.Category -Popularity2 -median_cylinder_by_vehicle_size -median_hp_by_vehicle_size, data = myData)
predicted <- predict.lm(myModel2)
summary(myModel2)

varImp(myModel2)

vif(myModel2)

```



```{r}

myModel3 = lm(MSRP ~ Engine.HP.Clean + Year, data = myData)
predicted <- predict.lm(myModel3)
summary(myModel3)

vif(myModel3)

```

train, test, and validation set splits
```{r}
set.seed(1234)

dim(myData)
splitPerc = .80
trainIndices = sample(1:dim(myData)[1],round(splitPerc * dim(myData)[1]))
train = myData[trainIndices,]
test.preSplit = myData[-trainIndices,]
dim(train)

# split the remaining 20% into 10% test and 10% validation
splitPerc.validation = .50
validationIndices = sample(1:dim(test.preSplit)[1], round(splitPerc.validation * dim(test.preSplit)[1]))
validation = test.preSplit[validationIndices,]
test = test.preSplit[-validationIndices,]
dim(validation)
dim(test)
```

Lasso Complex
``` {r}
matrixFormula <- function(data)
{
  # use fully saturated model with squared terms
  model.matrix(log(MSRP)~(.)^2, data)[, -1]
}


#Formatting data for GLM net
x_train= matrixFormula(train)
y_train=log(train$MSRP)
x_test<-matrixFormula(test)
y_test<-log(test$MSRP)
x_validation<-matrixFormula(validation)
y_validation <- log(validation$MSRP)

# Setting alpha = 1 implements lasso regression 
grid=10^seq(from=-3.0,to=0,by=0.1)
lasso_reg <- cv.glmnet(x_train, y_train, alpha=1, lambda =grid, scale=TRUE, center=TRUE)
plot(lasso_reg)
coefplot(lasso_reg)

#for loop here to iterate all ase's vs lambda's
getTestAse <- function(lambda) {
  pred <- predict(lasso_reg, s=lambda, newx=x_test)
  mean((y_test-pred)^2)
}

# Gather our Test ASE's from the lasso fit for different Constraint values (Lambda's)
TestAse <- data.frame(lambda = seq(from=.75*lasso_reg$lambda.min,to=1.25*lasso_reg$lambda.1se,by=0.00001))

# rowwise is needed here to make the getTestASE function run for every value of lambda....
TestAse <- TestAse %>% rowwise %>% mutate(Test_ASE=getTestAse(lambda))

# plot 
TestAse %>% ggplot(aes(x=log(lambda), y=Test_ASE)) + geom_point() + geom_vline(xintercept =log(lasso_reg$lambda.min), linetype="dashed", 
                color = "blue", size=0.5) + geom_text(aes(x=log(lasso_reg$lambda.min), label="\nLambda Min"), colour="blue",y=getTestAse(lasso_reg$lambda.min), text=element_text(size=11)) + geom_vline(xintercept =log(lasso_reg$lambda.1se), linetype="dashed", 
                color = "red", size=0.5) + geom_text(aes(x=log(lasso_reg$lambda.1se), label="\nLambda 1 SE"), colour="red",y=getTestAse(lasso_reg$lambda.min), text=element_text(size=11)) + ggtitle("Test ASE vs log Lambda")

## We use Lambda MIN, it works the best on our test set!

# Test
test_prediction=predict(lasso_reg,s=lasso_reg$lambda.min, newx=x_test)
test_ASE<-mean((y_test-test_prediction)^2)
test_ASE

# Validation
validation_prediction=predict(lasso_reg,s=lasso_reg$lambda.min, newx=x_validation)
validation_ASE<-mean((y_validation-validation_prediction)^2)
validation_ASE
```

R-Squared
```{r}
# R-Squared Train
rsq_train = 1 - lasso_reg$cvm/var(y_train)
rsq_train
plot(lasso_reg$lambda,rsq_train)
plotres(lasso_reg)
plot(lasso_reg$glmnet.fit, label=TRUE)

# R-Squared Test
pred <- predict(lasso_reg, s=lasso_reg$lambda.min, newx=x_test)
rss <- sum((y_test-pred)^2)
tss <- sum((y_test - mean(y_test)) ^ 2)
rsq <- 1 - rss/tss
rsq

# R-Squared Validation
pred <- predict(lasso_reg, s=lasso_reg$lambda.min, newx=x_validation)
rss <- sum((y_validation-pred)^2)
tss <- sum((y_validation - mean(y_validation)) ^ 2)
rsq <- 1 - rss/tss
rsq


glimpse(myData)

```



```{r}
# makes a dense matrix
coef(lasso_reg, s = "lambda.min")
df_coeff.lambda.min <- as.data.frame(as.matrix(coef(lasso_reg, s = "lambda.min"))) 

# This captures row names from the matrix dataframe
setDT(df_coeff.lambda.min, keep.rownames = TRUE)[] 

#Capture variables in readable names
df_coeff.lambda.min.clean <- df_coeff.lambda.min %>% mutate(variable=rn)
df_coeff.lambda.min.clean$estimate = df_coeff.lambda.min$`1`
df_coeff.lambda.min <- rename(df_coeff.lambda.min, estimate=`1`)
df_coeff.lambda.min <- rename(df_coeff.lambda.min, variable=rn)
df_coeff.lambda.min
df_coeff.lambda.min.clean <- df_coeff.lambda.min %>% filter(abs(estimate) > 0.000000e+00)
df_coeff.lambda.min.clean
```
```{r}
plot(cooks.distance(final.LASSOmodel))
ols_plot_cooksd_bar(lasso_reg$glmnet.fit)
cutoff <- 4/((nrow(mtcars)-length(fit$coefficients)-2))
plot(fit, which=4, cook.levels=cutoff)
# Influence Plot
influencePlot(fit, id.method="identify", main="Influence Plot", sub="Circle size is proportial to Cook's Distance" )

```

Backward-Selection for validation of Lasso
```{r}
# Forward Selection 
summary(train)
reg.bkwd=regsubsets(log(MSRP)~(.)^2,data=train,method="backward")
```


ASE plots
```{r}
bics<-summary(reg.bkwd)$bic
bics
plot(1:50,bics,type="l",ylab="BIC",xlab="# of predictors")
index<-which(bics==min(bics))
points(index,bics[index],col="red",pch=10)
print("Min Bics is:")
which(bics==min(bics))
 
# Adjr2
adjr2<-summary(reg.bkwd)$adjr2
plot(1:50,adjr2,type="l",ylab="Adjusted R-squared",xlab="# of predictors")
index<-which(adjr2==max(adjr2))
points(index,adjr2[index],col="red",pch=10)
print("Max Adj R2 is:")
which(adjr2==max(adjr2))
 
MallowCP <- summary(reg.bkwd)$cp
plot(1:50,MallowCP,type="l",ylab="Mallow's CP",xlab="# of predictors")
index<-which(MallowCP==min(MallowCP))
points(index,MallowCP[index],col="red",pch=10)
print("Min Mallow CP is:")
which(MallowCP==min(MallowCP))

```


KNN variable selection and test splits
```{r}
myData

myDataKNN <- myData[, c('Year', 'highway.MPG', 'city.mpg', 'Popularity', 'Engine.HP.Clean', 'MSRP')]
glimpse(myDataKNN)

# Scaling each column besides MSRP
preProc <- preProcess(myDataKNN[,-6],method=c('center','scale'))
myDataKNN_Scaled = predict(preProc, newdata=myDataKNN[-6])
myDataKNN_Scaled$MSRP = myDataKNN$MSRP

# tail(myDataKNN)
# tail(myDataKNN_Scaled)

set.seed(1234)
splitPercKNN = .80
trainIndicesKNN = sample(1:dim(myDataKNN_Scaled)[1],round(splitPercKNN * dim(myDataKNN_Scaled)[1]))
trainKNN = myDataKNN_Scaled[trainIndicesKNN,]
testKNN.preSplit = myDataKNN_Scaled[-trainIndicesKNN,]

# split the remaining 20% into 10% test and 10% validation
splitPerc.validation = .50
validationIndices = sample(1:dim(testKNN.preSplit)[1], round(splitPerc.validation * dim(testKNN.preSplit)[1]))
validationKNN = testKNN.preSplit[validationIndices,]
testKNN = testKNN.preSplit[-validationIndices,]

rf2 <- randomForest(MSRP~., data=myDataKNN_Scaled)
#rf2$importance
RFI2 <- as.data.frame(rf2$importance)
colnames(RFI2) = c("Influence")
RFI2 %>% slice_max(RFI2,n=3)

# preProc <- preProcess(trainKNN,method=c('center','scale'))
# scaledTrainKNN = predict(preProc, newdata=trainKNN)
# scaledTestKNN = predict(preProc, newdata=testKNN)

#sapply(myData, function(x) length(unique(x)))
myData %>%
  summarise_all(funs(sum(is.na(.))))


# KNN_Model1 <- knn.reg(train=trainKNN,   
#                      y=trainKNN$MSRP,
#                     test=testKNN,
#                      k=3)

```

Find Best K
```{r}
numks = 10
master_MSE = matrix(nrow = numks, ncol = 2)
for(i in 1:numks)
{
  KNN_Scaled_loop <- knn.reg(train=trainKNN,
                        y=trainKNN$MSRP,
                        test=testKNN,
                        k=i)
  
  residuals_KNN_loop <- testKNN$MSRP - KNN_Scaled_loop$pred
  SSE_KNN_Scaled_loop <- sum((residuals_KNN_loop) ^ 2)
  mse_KNN_Scaled_loop <- SSE_KNN_Scaled_loop/length(residuals_KNN_loop)
  master_MSE[i,1] = i
  master_MSE[i,2] = mse_KNN_Scaled_loop
}
plot(seq(1,numks,1),master_MSE[,2], type = "l", main="Test MSE vs number of K")

```

Run KNN with best (K USE K=4!!!)
```{r}

KNN_Scaled <- knn.reg(train=trainKNN,
                      y=trainKNN$MSRP,
                      test=testKNN,
                      k=4)
# KNN_Model1
# KNN_Model1_Scaled

#MSE for knn
# mse_KNN <- mean((KNN_Model1$pred - testKNN$MSRP) ^ 2)
# mse_KNN
#r2 for knn
#R2_KNN <- 1-mse_KNN/(var(testKNN$MSRP)) #168/169 is added to correct 
#R2_KNN
#MSE for knn scaled
residuals_KNN <- testKNN$MSRP - KNN_Scaled$pred
sse_KNN_Scaled <- sum((residuals_KNN) ^ 2)
mse_KNN_Scaled <- sse_KNN_Scaled/length(residuals_KNN)
print(mse_KNN_Scaled)
#r2 for knn scaled
# note: var() gives the sum total variance for a dataset
R2_KNN_Scaled <- 1-ase_KNN_Scaled/(var(testKNN$MSRP)) #168/169 is added to correct 
print(R2_KNN_Scaled)

plot(1:length(testKNN$MSRP), testKNN$MSRP, col = "red", type = "l", lwd=2,
     main = "Test vs Predicted KNN values")
lines(1:length(testKNN$MSRP), KNN_Scaled$pred, col = "blue", lwd=2)
lines(1:length(validationKNN$MSRP), validationKNN$MSRP, col = "green", lwd=2)
length(testKNN$MSRP)
length(validationKNN$MSRP)
# mean(y_test-(pred)^2)
head(KNN_Scaled$pred)
```


more EDA
```{r}
myData %>% ggplot(aes(x=Year, y=log(MSRP))) + geom_point()
myData %>% ggplot(aes(x=Year, y=log(MSRP))) + geom_smooth()

myData %>% ggplot(aes(x=highway.MPG, y=log(MSRP), colour=Engine.Fuel.Type)) + geom_point()
myData %>% ggplot(aes(x=highway.MPG, y=log(MSRP))) + geom_smooth()

myData %>% ggplot(aes(x=city.mpg, y=log(MSRP), colour=Engine.Fuel.Type)) + geom_point()
myData %>% ggplot(aes(x=city.mpg, y=log(MSRP))) + geom_smooth()

myData %>% ggplot(aes(x=Popularity, y=log(MSRP), colour=Engine.Fuel.Type)) +  geom_point() +
  geom_smooth(method = "nls", formula = y ~ a * x + b, se = F,
              method.args = list(start = list(a = 0.1, b = 0.1)))

myData %>% ggplot(aes(x=Engine.HP.Clean, y=log(MSRP), colour=Vehicle.Size)) + geom_point()
myData %>% ggplot(aes(x=Engine.HP.Clean, y=log(MSRP))) + geom_smooth()


tempModel <- lm(log(MSRP)~(.)^2, data=myData)
plot(tempModel)
coefplot(tempModel)
summary(tempModel)

```
